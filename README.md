# Constructing Adversarial Examples to Investigate the Plausibility of Explanations in Deep Audio and Image Classifiers

This repository will accompany the publication: 
Katharina Hoedt*, Verena Praher*, Arthur Flexer, and Gerhard Widmer, 
"Constructing Adversarial Examples to Investigate the Plausibility of Explanations in Deep Audio and Image Classifiers",
Neural Computing & Applications (2022). https://doi.org/10.1007/s00521-022-07918-7

(*) equal contribution.

The repository is currently still under construction; please stay tuned. If you want to get a preview of what it is to come, 
check out [this repository](https://github.com/CPJKU/veracity) for the code of the work that this paper is based on (i.e. all musical experiments). 
